{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RAVI GUPTA\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "# sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "akshar_image_folders = os.listdir(\"Devanagari\\Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_images = []\n",
    "\n",
    "list_of_labels = []\n",
    "\n",
    "label_index = 0\n",
    "\n",
    "for akshar_folder in akshar_image_folders:\n",
    "    \n",
    "    each_folder_path = os.path.join(\"Devanagari\\Train\",\n",
    "                                   akshar_folder)\n",
    "    \n",
    "    images = os.listdir(each_folder_path)\n",
    "    \n",
    "    img_shape = plt.imread(os.path.join(each_folder_path,images[0])).shape\n",
    "    \n",
    "    blank_array = np.zeros((len(images),(img_shape[0]*img_shape[1]))) \n",
    "    \n",
    "    blank_label_array = label_index*(np.ones((len(images),1)))\n",
    "    \n",
    "    index = 0\n",
    "    \n",
    "    for image in images:\n",
    "        \n",
    "        img_in_array = plt.imread(os.path.join(each_folder_path,image))\n",
    "        \n",
    "        blank_array[index] = img_in_array.reshape(1,(img_in_array.shape[0]*img_in_array.shape[1]))\n",
    "        \n",
    "        index += 1\n",
    "        \n",
    "    list_of_images.append(blank_array)\n",
    "    \n",
    "    list_of_labels.append(blank_label_array)\n",
    "    \n",
    "    label_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61200, 1024)\n",
      "(61200, 1)\n"
     ]
    }
   ],
   "source": [
    "tuple_of_label_arrays = tuple(list_of_labels)\n",
    "\n",
    "tuple_of_arrays = tuple(list_of_images)\n",
    "\n",
    "stacked_up_images = np.concatenate(tuple_of_arrays)\n",
    "\n",
    "print(stacked_up_images.shape)\n",
    "\n",
    "stacked_up_labels = np.concatenate(tuple_of_label_arrays)\n",
    "\n",
    "print(stacked_up_labels.shape)\n",
    "\n",
    "stacked_up_labels = np.int32(stacked_up_labels)\n",
    "\n",
    "rawdata = pd.DataFrame(stacked_up_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---one hot encoding of labels\n",
    "one_hot_labels = np.eye(len(akshar_image_folders),\n",
    "                        len(akshar_image_folders))[stacked_up_labels[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Importing keras model and necessary classes\n",
    "from keras.models import Model\n",
    "from keras.layers import Activation,Conv2D,Dense,MaxPool2D,Input,Flatten,BatchNormalization,Dropout\n",
    "# from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--input layer for entering of given data\n",
    "inp_layer = Input(shape=(32,32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Creating two convulational layer and before entering of data into next layer we applying batch normalization technique \n",
    "#  which improve accuracy drastically\n",
    "\n",
    "layer = Conv2D(filters=10,kernel_size=[5,5],activation=tf.nn.relu) (inp_layer)\n",
    "\n",
    "layer = BatchNormalization()(layer)\n",
    "\n",
    "layer = Conv2D(filters=10,kernel_size=[5,5],activation=tf.nn.relu) (layer)\n",
    "\n",
    "layer = BatchNormalization()(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--maxpooling the output of convulational layer and before the feeding into Fully Connected Layer\n",
    "#--and this technique help to reduce the no. units of neurons in any layer by downsampling\n",
    "\n",
    "layer = MaxPool2D(strides=(2,2)) (layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--streching a image to single row\n",
    "\n",
    "layer = Flatten() (layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Creating Two Fully Connected Hidden layer and also use Batch Normalization Techinque\n",
    "\n",
    "layer = Dense(units=16*16*10,activation=tf.nn.relu) (layer)\n",
    "\n",
    "layer = BatchNormalization()(layer)\n",
    "\n",
    "# layer = Dropout(rate=0.10)(layer)\n",
    "\n",
    "layer = Dense(units=16*16*10,activation=tf.nn.relu) (layer)\n",
    "\n",
    "layer = BatchNormalization()(layer)\n",
    "\n",
    "# layer = Dropout(rate = 0.10)(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--Ouput layer which contain 36 neurons for 36 classes\n",
    "\n",
    "layer = Dense(units=36,activation=tf.nn.softmax) (layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN = Model(inp_layer,layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- compiling the graph which is made above\n",
    "# tensorboard = TensorBoard(log_dir=\"logs/{}\".format('CNN_On_Devanagari_By_Keras'))\n",
    "\n",
    "CNN.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacked_up_images = stacked_up_images/255   --not effective technique in NN ..i think it generally reduce the variability of values which decrease the accuracy\n",
    "\n",
    "reshaped_data = np.reshape(stacked_up_images,(-1,32,32,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "61200/61200 [==============================] - 40s 647us/step - loss: 0.6541 - acc: 0.8546\n",
      "Epoch 2/2\n",
      "61200/61200 [==============================] - 37s 607us/step - loss: 0.1358 - acc: 0.9616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19103c46b00>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN.fit(x=reshaped_data,y=one_hot_labels,batch_size=500,epochs=2,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "models.Model.save(CNN,filepath = \"CNN_On_Devanagari.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.save(filepath = \"CNN_On_Devanagari_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre_Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "61200/61200 [==============================] - 32s 521us/step - loss: 0.0752 - acc: 0.9767\n",
      "Epoch 2/2\n",
      "61200/61200 [==============================] - 29s 482us/step - loss: 0.0448 - acc: 0.9862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19113809940>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = tf.keras.models.load_model(\"CNN_On_Devanagari.h5\")  #--it return the tensor object of your trained model\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy']) #--necessary step \n",
    "cnn.fit(x=reshaped_data,y=one_hot_labels,batch_size=500,epochs=2)  # it is used to improve further the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general use case is to use BN between the linear and non-linear layers in your network, because it normalizes the input to your activation function, so that you're centered in the linear section of the activation function (such as Sigmoid).\n",
    "\n",
    "the point is that we're trying to normalize the inputs to a layer, so it should always go immediately before the next layer in the network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
